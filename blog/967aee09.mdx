---
authors:
- PuQing
date: 2023-07-22 21:42
keywords:
- 统计学
- 概率论
tags:
- 统计学
- 概率论
---
# 极大似然估计

Maximum Likelihood Estimation(MLE) 极大似然估计，又被称作最大似然估计。其可在给定概率分布模型的条件下用于模型参数的估计，即所谓的参数估计

## 基本原理

对于一个常见的随机变量 $P(x;\theta)$，其中的 $x$ 是表示随机变量，$\theta$ 是该概率分布模型的模型参数。在不同的模型下有各自的模型参数，比如 [二项分布(This page not published)](./404) $p$，[正态分布(This page not published)](./404) 的 $\mu,\sigma$。

:::example 正态分布
连续型随机变量 $X$ 如果满足如下密度函数


<!--truncate-->
$$
f(x)=\frac{1}{\sqrt{2 \pi} \sigma} e^{-\frac{(x-\mu)^{2}}{2 \sigma^{2}}} \quad(\mu \in R, \sigma> 0)
$$
则称 $X$ 服从参数为 $(\mu,\sigma^2)$ 的正态分布，记为 $X\sim N(\mu,\sigma^2)$

:::
在一般情况下是给定概率分布的模型参数 $\theta$，这此时的 $P(x;\theta)$ 便是在确定的参数下随机变量 $x$ 的概率；但是反过来，如果随机变量 $x$ 是已知的，**则此时的 $P(x;\theta)$ 便是在不同的模型参数 $\theta$ 下给出定样本 $x$ 的概率**。显然在参数估计的过程中对 $P(x;\theta)$ 取后一种理解。

所谓参数估计，就是估计出概率分布中的模型参数 $\theta$。为此会首先进行 $n$ 次抽样检验，记该结果为 $x_1,x_2,\cdots,x_n$。我们需要根据这 $n$ 个抽样结果，估计出概率分布的模型参数。这就是本文的主题 --MLE 极大似然估计。其依据的思想也很简单，即概率越大越有可能发生 (最大似然可以理解为最为相似，即最大的可能性)。即使得当前抽样结果发生概率 $L(\theta)$ 最大的模型参数 $\theta$，就是我们所需的参数估计值。即

$$
\underset{\theta}{\arg \max } L(\theta)=\underset{\theta}{\arg \max } L\left(x_{1}, x_{2}, \ldots, x_{n} ; \theta\right)=\underset{\theta}{\arg \max } P\left(x_{1}, x_{2}, \ldots, x_{n} ; \theta\right)
$$
::::tip hold on 这里神奇的符号是什么意思？
其中的 $P(x_1,x_2,\cdots,x_n;\theta)$ 根据我们上面的讲解是当确定 $x_1,x_2,\cdots,x_n$ 时模型参数 $\theta$ 的概率，而 $\underset{\theta}{\arg \max}$ 则是使该概率最大的 $\theta$ 值。
如果还是有些抽象可以看看下面的栗子

🌰🌰🌰🌰🌰

不好意思，举错了

:::example

- $\displaystyle\underset{x}{\arg \min} x^2$：表示使 $x^2$ 最小的 $x$ 值，显然为 $0$
- $\displaystyle\underset{\theta}{\arg \max}\log{\theta}\sin{\theta}+\theta$：显然我们需要先求导，然后寻找极值点，然后确定最大值。所用同样的，如下文

:::
::::
其中的 $L(\theta)$ 称为样本的似然函数。大多数的情况下，$n$ 次抽样检查互相之间满足独立同分布 $i.i.d$，则有

$$
\underset{\theta}{\arg \max } L\left(x_{1}, x_{2}, \ldots, x_{n} ; \theta\right)=\underset{\theta}{\arg \max } \prod_{i=1}^{n} P\left(x_{i} ; \theta\right)
$$
::::note i.i.d
独立同分布 independent and identically distributed，i.i.d.[^1]

:::info
指随机过程中，任何时刻的取值都为随机变量，如果这些随机变量服从同一分布，并且互相独立，那么这些随机变量是独立同分布。


:::
::::
所以 MLE 极大似然估计在参数估计过程中的基本步骤：

1. 建立似然函数 $L(\theta)$
2. 对 $L(\theta)$ 取对数，得对数似然函数 $\ln L(\theta)$
3. $\ln L(\theta)$ 对 $\theta$ 求导并令其为 $0$，计算极值点
4. 模型参数 $\theta$ 得解

:::warning 为什么需要取对数呢？
[Log Derivative Trick(This page not published)](./404)

:::
## 离散型概率分布

说了这么多，我们通过一个实际例子来展示如何具体的通过 MLE 来进行参数估计。这里我们以离散型概率分布中的二项分布为例

:::example
有一个不透明的袋子，里面装了黑、白两种颜色的球。记从袋子中摸到黑球、白球的概率分别为 $p$、$1-p$。假设某人进行了 $10$ 次随机抽样，每次都是有放回的从袋子中摸出一个球，其抽样结果为 $7$ 次黑球、$3$ 次白球。试估计出概率 $p$ 的值

:::
首先建立似然函数 $L(p)$。显然该分布为二项分布，同时满足 $i.i.d$。所以我们可以取：

$$
L(p)=L\left(x_{1}, x_{2}, \ldots, x_{10} ; p\right)=\prod_{i=1}^{10} P\left(x_{i} ; p\right)=p^{7} \cdot(1-p)^{3}
$$
:::tip Hold on. 这里得 $p^7\cdot (1-p)^3$ 是怎么出现的？
前面我们已经说了 $P(x;\theta)$ 具有两面性，可以理解为在参数 $\theta$ 下得到 $x$ 的概率，具体来说，对于二项分布，如果已知参数 $p$，则取到黑色的概率为 $p$，取到白色的概率为 $1-p$，我想这是再自然不过的事情了；
因为所有的随机变量都是独立同分布的，所以都满足模型参数 $p$ 下的二项分布。那我们假设此时的参数为 $p$(十个概率模型都是这个 $p$)，则取十次的联合分布为连乘。就得到上面的式子。

:::
对其取对数

$$
\ln L(p)=7 \cdot \ln p+3 \cdot \ln (1-p)
$$
对其求导并令其为 $0$，有

$$
(\ln L(p))^{\prime}=\frac{7}{p}-\frac{3}{1-p}=0
$$
最后，求解上式可得 $p=0.7$

## 连续型概率分布

在连续型概率分布中，其不存在分布律，取而代之的是概率密度函数 $f$。则对于 $n$ 个样本而言，可以写出连续型概率分布下的似然函数为

$$
L(\theta)=L\left(x_{1}, x_{2}, \ldots, x_{n} ; \theta\right)=\prod_{i=1}^{n} f\left(x_{i} ; \theta\right)
$$
这里假设样本符合正态分布，则我们可以带入正态分布的概率密度函数：

$$
\begin{aligned}
L\left(\mu, \sigma^{2}\right) & =\prod_{i=1}^{n} f\left(x_{i} ; \mu, \sigma^{2}\right) \\
& =\prod_{i=1}^{n} \frac{1}{\sqrt{2 \pi} \cdot \sigma} \cdot e^{-\frac{\left(x_{i}-\mu\right)^{2}}{2 \sigma^{2}}} \\
& =\left(\frac{1}{\sqrt{2 \pi} \cdot \sigma}\right)^{n} \cdot e^{-\sum_{i=1}^{n} \frac{\left(x_{i}-\mu\right)^{2}}{2 \sigma^{2}}} \\
& =\left(2 \pi \cdot \sigma^{2}\right)^{-\frac{n}{2}} \cdot e^{-\sum_{i=1}^{n} \frac{\left(x_{i}-\mu\right)^{2}}{2 \sigma^{2}}}
\end{aligned}
$$
对其取对数

$$
\begin{aligned}
\ln L\left(\mu, \sigma^{2}\right) & =-\frac{n}{2} \cdot \ln \left(2 \pi \cdot \sigma^{2}\right)-\sum_{i=1}^{n} \frac{\left(x_{i}-\mu\right)^{2}}{2 \sigma^{2}} \\
& =-\frac{n}{2}\left[\ln (2 \pi)+\ln \left(\sigma^{2}\right)\right]-\frac{1}{2 \sigma^{2}} \sum_{i=1}^{n}\left(x_{i}-\mu\right)^{2}
\end{aligned}
$$
分别对模型参数求偏导数并令其为 $0$，有

$$
\begin{cases}
\frac{\partial \ln L}{\partial \mu}=\frac{1}{\sigma^{2}} \cdot \sum_{i=1}^{n}\left(x_{i}-\mu\right)=0 \\
\frac{\partial \ln L}{\partial \sigma^{2}}=-\frac{n}{2 \sigma^{2}}+\frac{1}{2 \sigma^{4}} \sum_{i=1}^{n}\left(x_{i}-\mu\right)^{2}=0
\end{cases}
$$
最后，求解上式子，可得到正态分布的模型参数在 MLE 下的估计值：

$$
\begin{cases}
\mu=\frac{1}{n} \sum_{i=1}^{n} x_{i} \\
\sigma^{2}=\frac{1}{n} \sum_{i=1}^{n}\left(x_{i}-\mu\right)^{2}
\end{cases}
$$
所以对于正态分布而言，其均值的极大似然估计量即是样本的均值；而其方差的极大似然估计量却是**样本数据的总体方差值 (即分母为 $n$)** ，而不是 **样本数据的样本方差值 (即分母为 $n-1$)**[(这里为什么是n-1)](./8f979ab4#%5E187511) ，故正态分布方差的极大似然估计量是有偏的。

:::danger
在最后一步，对于多元函数求极值可能需要证明，根据 [多元函数的极值 最大值与最小值](./8145550f) 中的描述，其偏导为零只是必要条件，而并非充要条件。其应满足似然函数的 $\mathrm{Hessan}$ 矩阵为负正定。

:::
## 相关资料

- [Maximum Likelihood Estimation(MLE) 极大似然估计](https://zhuanlan.zhihu.com/p/163258672)
- [Maximum_likelihood_Wikipedia.pdf](https://www.ccs.neu.edu/home/vip/teach/MLcourse/3_generative_models/lecture_notes/Maximum_likelihood_Wikipedia.pdf)

[^1]: [独立同分布 independent and identically distributed](https://zhuanlan.zhihu.com/p/52530189)
